{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Import the libraries and modules\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from flask import Flask, render_template, redirect\n",
    "from flask_pymongo import PyMongo\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize Browser function from splinter library (necessary to begin all scrape functions below).\n",
    "def init_browser():\n",
    "    # @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {\"executable_path\": \"chromedriver\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Run Scrape functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.1.a\n",
    "# First Scrape: Scrape latest headine and subheadline from mars.nasa.gov/news/\n",
    "def scrape_mars_info():\n",
    "    browser = init_browser()\n",
    "\n",
    "    # Visit visitcostarica.herokuapp.com\n",
    "    url = \"https://mars.nasa.gov/news/\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # Get the headline\n",
    "    title = soup.find('div', class_='content_title')\n",
    "    title_text = title.text\n",
    "\n",
    "    # Get the subhead\n",
    "    paragraph = soup.find('div', class_='article_teaser_body')\n",
    "    p_text = paragraph.text\n",
    "\n",
    "    # Store data in a dictionary\n",
    "    headlines = {\n",
    "        \"headline\": title_text,\n",
    "        \"subhead\": p_text\n",
    "    }\n",
    "\n",
    "    # Close the browser after scraping\n",
    "    browser.quit()\n",
    "\n",
    "    # Return results\n",
    "    return headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': 'Mars InSight Lander Seen in First Images from Space ',\n",
       " 'subhead': \"Look closely, and you can make out the lander's solar panels.\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3.1.b\n",
    "# First scrape verification.  Headline and subhead returned as python dictionary.\n",
    "scrape_mars_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.2.a\n",
    "# Second scrape: Scrape featured image from jpl.nasa.gov/spaceimages.  Make sure image is full size jpg.\n",
    "def scrape_mars_img():\n",
    "    browser = init_browser()\n",
    "    # Visit visitcostarica.herokuapp.com\n",
    "    url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # Get the current img\n",
    "    url_text = soup.select('article.carousel_item')[0]['style']\n",
    "    partial_url = re.search(\"(?<=').+(?=')\",url_text).group()\n",
    "    full_url = \"https://www.jpl.nasa.gov\" + partial_url\n",
    "\n",
    "    # Store data in a dictionary\n",
    "    img_dict = {\n",
    "        \"featured_image_url\": full_url\n",
    "        }\n",
    "\n",
    "    #Close the browser after scraping\n",
    "    browser.quit()\n",
    "\n",
    "    return img_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'featured_image_url': 'https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA19974-1920x1200.jpg'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3.2.b\n",
    "# Second scrape verification.  Image returned as python dictionary.\n",
    "scrape_mars_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.3.a\n",
    "# Third Scrape: Scrape latest Mars weather from Mars Weather Twitter page.\n",
    "# Note: Tweets are not always weather. Non-weather tweets will not render correctly in html.\n",
    "def scrape_mars_weather():\n",
    "    browser = init_browser()\n",
    "\n",
    "    # Visit visitcostarica.herokuapp.com\n",
    "    url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # Get the latest tweet\n",
    "    tweet = soup.find('div', class_='js-tweet-text-container')\n",
    "    mars_weather = tweet.text\n",
    "\n",
    "    # Store data in a dictionary\n",
    "    latest_tweet = {\n",
    "        \"mars_weather\": mars_weather\n",
    "    }\n",
    "\n",
    "    # Close the browser after scraping\n",
    "    browser.quit()\n",
    "\n",
    "    # Return results\n",
    "    return latest_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mars_weather': '\\nThe InSight lander, discarded heatshield, back shell and parachute have been spotted from orbit by the @HiRISE camera aboard the Mars Reconnaissance Orbiter  https://www.uahirise.org/releases/insight/hardware/\\xa0â€¦pic.twitter.com/6BM7QMWrU4\\n'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3.3.b: \n",
    "# Third scrape verification.  Weather returned as python dictionary.\n",
    "scrape_mars_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.4.a\n",
    "# Fourth Scrape: Parse Mars Fact table from space-facts.com/mars\n",
    "# Parsed HTML table using requests and beautifulsoup. Results from two functions saved in a class.\n",
    " \n",
    "url = \"https://space-facts.com/mars/\"\n",
    "response = requests.get(url)\n",
    "response.text[:100] # Access the HTML with the text property\n",
    "\n",
    "# Create class to hold results of parse_url and parse_html_table functions\n",
    "class HTMLTableParser:\n",
    "\n",
    "    def parse_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        return [(table['id'],self.parse_html_table(table))\\\n",
    "                for table in soup.find_all('table')]  \n",
    "\n",
    "    def parse_html_table(self, table):\n",
    "        n_columns = 0\n",
    "        n_rows=0\n",
    "        column_names = []\n",
    "\n",
    "        # Find number of rows and columns\n",
    "        # we also find the column titles if we can\n",
    "        for row in table.find_all('tr'):\n",
    "\n",
    "            # Determine the number of rows in the table\n",
    "            td_tags = row.find_all('td')\n",
    "            if len(td_tags) > 0:\n",
    "                n_rows+=1\n",
    "                if n_columns == 0:\n",
    "                    # Set the number of columns for our table\n",
    "                    n_columns = len(td_tags)\n",
    "\n",
    "            # Handle column names if we find them\n",
    "            th_tags = row.find_all('th') \n",
    "            if len(th_tags) > 0 and len(column_names) == 0:\n",
    "                for th in th_tags:\n",
    "                    column_names.append(th.get_text())\n",
    "\n",
    "        # Safeguard on Column Titles\n",
    "        if len(column_names) > 0 and len(column_names) != n_columns:\n",
    "            raise Exception(\"Column titles do not match the number of columns\")\n",
    "\n",
    "        columns = column_names if len(column_names) > 0 else range(0,n_columns)\n",
    "        df = pd.DataFrame(columns = columns,\n",
    "                          index= range(0,n_rows))\n",
    "        row_marker = 0\n",
    "        for row in table.find_all('tr'):\n",
    "            column_marker = 0\n",
    "            columns = row.find_all('td')\n",
    "            for column in columns:\n",
    "                df.iat[row_marker,column_marker] = column.get_text()\n",
    "                column_marker += 1\n",
    "            if len(columns) > 0:\n",
    "                row_marker += 1\n",
    "\n",
    "        # Convert to float if possible\n",
    "        for col in df:\n",
    "            try:\n",
    "                df[col] = df[col].astype(float)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Equatorial Diameter:</td>\n",
       "      <td>6,792 km\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polar Diameter:</td>\n",
       "      <td>6,752 km\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mass:</td>\n",
       "      <td>6.42 x 10^23 kg (10.7% Earth)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moons:</td>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orbit Distance:</td>\n",
       "      <td>227,943,824 km (1.52 AU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Orbit Period:</td>\n",
       "      <td>687 days (1.9 years)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Surface Temperature:</td>\n",
       "      <td>-153 to 20 Â°C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>First Record:</td>\n",
       "      <td>2nd millennium BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recorded By:</td>\n",
       "      <td>Egyptian astronomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0                              1\n",
       "0   Equatorial Diameter:                     6,792 km\\n\n",
       "1        Polar Diameter:                     6,752 km\\n\n",
       "2                  Mass:  6.42 x 10^23 kg (10.7% Earth)\n",
       "3                 Moons:            2 (Phobos & Deimos)\n",
       "4        Orbit Distance:       227,943,824 km (1.52 AU)\n",
       "5          Orbit Period:         687 days (1.9 years)\\n\n",
       "6  Surface Temperature:                   -153 to 20 Â°C\n",
       "7          First Record:              2nd millennium BC\n",
       "8           Recorded By:           Egyptian astronomers"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.4.b\n",
    "# Put result of HTMLParser class into variable\n",
    "hp = HTMLTableParser()\n",
    "# 3.4.c\n",
    "# Put table variable into pandas DataFrame \n",
    "table = hp.parse_url(url)[0][1] # Grabbing the table from the tuple\n",
    "# 3.4.d\n",
    "# Call variable to verify table returned as python DataFrame.\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe table\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th>0</th>\\n      <th>1</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <td>Equatorial Diameter:</td>\\n      <td>6,792 km\\\\n</td>\\n    </tr>\\n    <tr>\\n      <td>Polar Diameter:</td>\\n      <td>6,752 km\\\\n</td>\\n    </tr>\\n    <tr>\\n      <td>Mass:</td>\\n      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n    </tr>\\n    <tr>\\n      <td>Moons:</td>\\n      <td>2 (Phobos & Deimos)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Distance:</td>\\n      <td>227,943,824 km (1.52 AU)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Period:</td>\\n      <td>687 days (1.9 years)\\\\n</td>\\n    </tr>\\n    <tr>\\n      <td>Surface Temperature:</td>\\n      <td>-153 to 20 Â°C</td>\\n    </tr>\\n    <tr>\\n      <td>First Record:</td>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <td>Recorded By:</td>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.4.e\n",
    "# Convert DataFrame into HTML\n",
    "html_table = table.to_html(classes='table',index=False,escape=False)\n",
    "html_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"dataframe table\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th>0</th>\\n      <th>1</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <td>Equatorial Diameter:</td>\\n      <td>6,792 km\\\\n</td>\\n    </tr>\\n    <tr>\\n      <td>Polar Diameter:</td>\\n      <td>6,752 km\\\\n</td>\\n    </tr>\\n    <tr>\\n      <td>Mass:</td>\\n      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n    </tr>\\n    <tr>\\n      <td>Moons:</td>\\n      <td>2 (Phobos & Deimos)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Distance:</td>\\n      <td>227,943,824 km (1.52 AU)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Period:</td>\\n      <td>687 days (1.9 years)\\\\n</td>\\n    </tr>\\n    <tr>\\n      <td>Surface Temperature:</td>\\n      <td>-153 to 20 Â°C</td>\\n    </tr>\\n    <tr>\\n      <td>First Record:</td>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <td>Recorded By:</td>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth Scrape Condensed for copy/paste purposes into scrape_mars.py file.\n",
    "\n",
    "url = \"https://space-facts.com/mars/\"\n",
    "response = requests.get(url)\n",
    "response.text[:100] # Access the HTML with the text property\n",
    "\n",
    "# Create class to hold results of parse_url and parse_html_table functions\n",
    "class HTMLTableParser:\n",
    "\n",
    "    def parse_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        return [(table['id'],self.parse_html_table(table))\\\n",
    "                for table in soup.find_all('table')]  \n",
    "\n",
    "    def parse_html_table(self, table):\n",
    "        n_columns = 0\n",
    "        n_rows=0\n",
    "        column_names = []\n",
    "\n",
    "        # Find number of rows and columns\n",
    "        # we also find the column titles if we can\n",
    "        for row in table.find_all('tr'):\n",
    "\n",
    "            # Determine the number of rows in the table\n",
    "            td_tags = row.find_all('td')\n",
    "            if len(td_tags) > 0:\n",
    "                n_rows+=1\n",
    "                if n_columns == 0:\n",
    "                    # Set the number of columns for our table\n",
    "                    n_columns = len(td_tags)\n",
    "\n",
    "            # Handle column names if we find them\n",
    "            th_tags = row.find_all('th') \n",
    "            if len(th_tags) > 0 and len(column_names) == 0:\n",
    "                for th in th_tags:\n",
    "                    column_names.append(th.get_text())\n",
    "\n",
    "        # Safeguard on Column Titles\n",
    "        if len(column_names) > 0 and len(column_names) != n_columns:\n",
    "            raise Exception(\"Column titles do not match the number of columns\")\n",
    "\n",
    "        columns = column_names if len(column_names) > 0 else range(0,n_columns)\n",
    "        df = pd.DataFrame(columns = columns,\n",
    "                          index= range(0,n_rows))\n",
    "        row_marker = 0\n",
    "        for row in table.find_all('tr'):\n",
    "            column_marker = 0\n",
    "            columns = row.find_all('td')\n",
    "            for column in columns:\n",
    "                df.iat[row_marker,column_marker] = column.get_text()\n",
    "                column_marker += 1\n",
    "            if len(columns) > 0:\n",
    "                row_marker += 1\n",
    "\n",
    "        # Convert to float if possible\n",
    "        for col in df:\n",
    "            try:\n",
    "                df[col] = df[col].astype(float)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        return df\n",
    "        # Use HTML TableParser to parse results into table\n",
    "        hp = HTMLTableParser()\n",
    "        # Put table variable into pandas DataFrame \n",
    "        table = hp.parse_url(url)[0][1] # Grabbing the table from the tuple\n",
    "        # Convert DataFrame into HTML\n",
    "        html_table = table.to_html(classes='table',index=False,escape=False)\n",
    "        # Delete leading '\\n' table characters\n",
    "        html_table.replace('\\n', '')\n",
    "        # Return HTML\n",
    "        return html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cerberus Hemisphere Enhanced',\n",
       " 'Schiaparelli Hemisphere Enhanced',\n",
       " 'Syrtis Major Hemisphere Enhanced',\n",
       " 'Valles Marineris Hemisphere Enhanced']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4.1.a\n",
    "# Fifth Scrape: Scrape titles and image URLs from astrogeology.usgs.gov/search/results.  \n",
    "# Store results as lists within dictionary inside a single list. First the titles.\n",
    "url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(url)\n",
    "time.sleep(3)\n",
    "page_source = browser.html\n",
    "soup = bs(page_source,\"lxml\")\n",
    "hemisphere_titles = [x.text for x in soup.select(\"h3\")]\n",
    "# Call variable to verify titles stored as a list\n",
    "hemisphere_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1.b\n",
    "# Then the image URLs.\n",
    "all_links = [\"https://astrogeology.usgs.gov\" + x[\"href\"] for x in soup.select(\".item > .product-item\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1.c\n",
    "# Render image verification\n",
    "browser.visit(all_links[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg',\n",
       " 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg',\n",
       " 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg',\n",
       " 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1.d\n",
    "# Load URLs into image_links list\n",
    "image_links = []\n",
    "for link in all_links:\n",
    "    browser.visit(link)\n",
    "    page_source = browser.html\n",
    "    soup = bs(page_source,\"lxml\")\n",
    "    image_link = \"https://astrogeology.usgs.gov\" + str(soup.select(\".wide-image\")[0][\"src\"])\n",
    "    image_links.append(image_link)\n",
    "image_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere Enhanced',\n",
       "  'image_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg'},\n",
       " {'title': 'Schiaparelli Hemisphere Enhanced',\n",
       "  'image_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg'},\n",
       " {'title': 'Syrtis Major Hemisphere Enhanced',\n",
       "  'image_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg'},\n",
       " {'title': 'Valles Marineris Hemisphere Enhanced',\n",
       "  'image_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1.e\n",
    "# Zip titles list and image list into dictionary.  Put that dictionary into a list.\n",
    "# Initialize empty singular parent list\n",
    "list1 = []\n",
    "# Function to zip lists into dictionary \n",
    "for x,y in zip (hemisphere_titles,image_links):\n",
    "    # Dictionary to house lists\n",
    "    temp_dict = {\"title\":x,\"image_url\":y}\n",
    "    # Append the dictionary to the empty list\n",
    "    list1.append(temp_dict)\n",
    "# Verify list contains the dictionary of both lists.\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fifth Scrape Condensed for copy/paste purposes into scrape_mars.py file.\n",
    "def scrape_mars_hemisphere():\n",
    "    browser = init_browser()\n",
    "    #go to url\n",
    "    url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "    browser.visit(url)\n",
    "    time.sleep(3)\n",
    "    page_source = browser.html\n",
    "    soup = bs(page_source,\"lxml\")\n",
    "    \n",
    "    #get the titles\n",
    "    hemisphere_titles = [x.text for x in soup.select(\"h3\")]\n",
    "    \n",
    "    #get the links\n",
    "    all_links = [\"https://astrogeology.usgs.gov\" + x[\"href\"] \\\n",
    "        for x in soup.select(\".item > .product-item\")]\n",
    "    image_links = []\n",
    "    \n",
    "    for link in all_links:\n",
    "        browser.visit(link)\n",
    "        page_source = browser.html\n",
    "        soup = bs(page_source,\"lxml\")\n",
    "        image_link = \"https://astrogeology.usgs.gov\" + str(soup.select(\".wide-image\")[0][\"src\"])\n",
    "        image_links.append(image_link)\n",
    "    \n",
    "    #zip titles and links into dictionary within a list\n",
    "    hemispheres_list = []\n",
    "    for x,y in zip(hemisphere_titles,image_links):\n",
    "        hemispheres_dict = {\"title\":x,\"image_url\":y}\n",
    "        hemispheres_list.append(hemispheres_dict)\n",
    "\n",
    "    # Close the browser after scraping\n",
    "    browser.quit()\n",
    "\n",
    "    # Return results\n",
    "    return hemispheres_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Put scrape results from each function into a dictionary\n",
    "def scrape():\n",
    "     scraped_data = {\n",
    "         \"headlines_dict\":scrape_mars_info(),\n",
    "         \"img_dict\":scrape_mars_img(),\n",
    "         \"weather_dict\":scrape_mars_weather(),\n",
    "         \"table_list\":html_table,\n",
    "         \"hemispheres_list\":scrape_mars_hemisphere()\n",
    "     }\n",
    "     return scraped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headlines_dict': {'headline': \"NASA's InSight Takes Its First Selfie\",\n",
       "  'subhead': 'Two new image mosaics detail the lander\\'s deck and \"workspace\" â€” the surface where it will eventually set down its science instruments.'},\n",
       " 'img_dict': {'featured_image_url': 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars/assets/images/logo_nasa_trio_black@2x.png'},\n",
       " 'weather_dict': {'mars_weather': '\\nSol 2255 (2018-12-10), high -11C/12F, low -71C/-95F, pressure at 8.41 hPa, daylight 06:36-18:50\\n'},\n",
       " 'table_list': '<table border=\"1\" class=\"dataframe table\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th>0</th>\\n      <th>1</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <td>Equatorial Diameter:</td>\\n      <td>6,792 km\\\\n</td>\\n    </tr>\\n    <tr>\\n      <td>Polar Diameter:</td>\\n      <td>6,752 km\\\\n</td>\\n    </tr>\\n    <tr>\\n      <td>Mass:</td>\\n      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n    </tr>\\n    <tr>\\n      <td>Moons:</td>\\n      <td>2 (Phobos & Deimos)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Distance:</td>\\n      <td>227,943,824 km (1.52 AU)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Period:</td>\\n      <td>687 days (1.9 years)\\\\n</td>\\n    </tr>\\n    <tr>\\n      <td>Surface Temperature:</td>\\n      <td>-153 to 20 Â°C</td>\\n    </tr>\\n    <tr>\\n      <td>First Record:</td>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <td>Recorded By:</td>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>',\n",
       " 'hemispheres_list': [{'title': 'Cerberus Hemisphere Enhanced',\n",
       "   'image_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg'},\n",
       "  {'title': 'Schiaparelli Hemisphere Enhanced',\n",
       "   'image_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg'},\n",
       "  {'title': 'Syrtis Major Hemisphere Enhanced',\n",
       "   'image_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg'},\n",
       "  {'title': 'Valles Marineris Hemisphere Enhanced',\n",
       "   'image_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1.b\n",
    "# Scrape dictionary verification\n",
    "scrape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"dataframe table\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th>0</th>\\n      <th>1</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <td>Equatorial Diameter:</td>\\n      <td>6,792 km\\\\n</td>\\n    </tr>\\n    <tr>\\n      <td>Polar Diameter:</td>\\n      <td>6,752 km\\\\n</td>\\n    </tr>\\n    <tr>\\n      <td>Mass:</td>\\n      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n    </tr>\\n    <tr>\\n      <td>Moons:</td>\\n      <td>2 (Phobos & Deimos)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Distance:</td>\\n      <td>227,943,824 km (1.52 AU)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Period:</td>\\n      <td>687 days (1.9 years)\\\\n</td>\\n    </tr>\\n    <tr>\\n      <td>Surface Temperature:</td>\\n      <td>-153 to 20 Â°C</td>\\n    </tr>\\n    <tr>\\n      <td>First Record:</td>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <td>Recorded By:</td>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
